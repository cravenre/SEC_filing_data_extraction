{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of files in the target folder to use for extracting information from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all the files containing SEC filing forms so we can use it for functions, all we need to do is\n",
    "# insert the file directory in the function\n",
    "\n",
    "file_list = []\n",
    "\n",
    "def file_grabber(directory):\n",
    "    files = os.listdir(directory)\n",
    "    for file in files:\n",
    "        if file.endswith('.htm'):\n",
    "            file_list.append(file)\n",
    "\n",
    "file_grabber('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ISIN code from each file and adding to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to add ID information to (filing_ID_list) and creating a function to extract the ISIN ID\n",
    "\n",
    "# Defining the empty dataframe to be filled\n",
    "filing_ID_list = []\n",
    "\n",
    "# Defining the function to pull the ISIN id and file name based on a given list of files (list_of_files)\n",
    "def ISIN_extractor(list_of_files):\n",
    "    for file in list_of_files: # Loop over each file in the list\n",
    "        page = open('data/'+file) # Opening the file from the 'data' folder\n",
    "        ISIN_code = BS(page.read()).text.lower() # Use BeautifulSoup to pull the html text in and convert to lowercase\n",
    "    \n",
    "        ISIN_code = re.findall('(?<=isin).*', ISIN_code, re.DOTALL) # Extract all text found after the 'isin' pattern\n",
    "    \n",
    "        ISIN_code = list(set(re.findall('[a-z]{2}\\d{5}[a-z\\d]{3}\\d{2}', str(ISIN_code)))) # Add ISIN code patterns\n",
    "                                                                                          # found to a list once\n",
    "    \n",
    "        filing_ID_list.append((file, ISIN_code)) # Add each file name and ISIN code to a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ISIN code extracting function on the list of files created above\n",
    "ISIN_extractor(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists to a dataframe (filing_ID_list)\n",
    "filing_ID_list = pd.DataFrame(filing_ID_list, columns=['file', 'ISIN_id'])\n",
    "filing_ID_list = pd.DataFrame(filing_ID_list.ISIN_id.values.tolist(), filing_ID_list.file).add_prefix('ISIN_id_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to contain a list of additional ISIN id's so we can identify files that may warrant investigation\n",
    "filing_ID_list['extra_ISIN'] = filing_ID_list[filing_ID_list.columns[2:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1)\n",
    "\n",
    "# Removing unnecessary columns and renmaing the ISIN id column\n",
    "filing_ID_list = filing_ID_list[['file', 'ISIN_id_0', 'extra_ISIN']].rename(columns={'ISIN_id_0':'ISIN_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the CUSIP code from each file based on ISIN code and file text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CUSIP id column based on removing additional components (2-digit prefix, 1-digit suffix) from ISIN ID\n",
    "filing_ID_list['CUSIP_id'] = filing_ID_list['ISIN_id'].str[2:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since not every file has an associated ISIN ID, we need to extract missing CUSIP ID's for those files.\n",
    "# The below function pulls out CUSIP ID values from the list of file names similar to how ISIN ID's were pulled out\n",
    "\n",
    "CUSIP_list = []\n",
    "\n",
    "def CUSIP_extractor(list_of_files):\n",
    "    for file in list_of_files:\n",
    "        try:\n",
    "            page = open('data/'+file)\n",
    "            file_name = BS(page.read()).text.lower()\n",
    "    \n",
    "            file_name = re.search('(?<=cusip).*', file_name, re.DOTALL).group()\n",
    "    \n",
    "            file_name = re.search('\\d{5}[a-z\\d]{3}\\d', str(file_name)).group() # This pulls out the first pattern match\n",
    "                                                                               # instead of each pattern match for ISIN\n",
    "        \n",
    "        except:\n",
    "            file_name = 'none'\n",
    "    \n",
    "        CUSIP_list.append((file, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to pull out first CUSIP ID pattern match\n",
    "CUSIP_extractor(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CUSIP ID list of lists into a dataframe. Name CUSIP column as 'alternates' to merge with full ID list\n",
    "CUSIP_list = pd.DataFrame(CUSIP_list, columns=['file', 'CUSIP_id_alternate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check to ensure the CUSIP ID list looks good\n",
    "CUSIP_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the full ID list dataframe with the alternate CUSIP dataframe to fill in missing CUSIP ID values\n",
    "filing_ID_list = filing_ID_list.merge(CUSIP_list, on='file')\n",
    "\n",
    "# Fill in the missing CUSIP ID's from the CUSIP alternate column\n",
    "filing_ID_list.CUSIP_id.fillna(value=filing_ID_list['CUSIP_id_alternate'], inplace=True)\n",
    "\n",
    "# Drop the alternate CUSIP column since no longer needed\n",
    "filing_ID_list = filing_ID_list.drop('CUSIP_id_alternate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return ISIN id and CUSIP id to uppercase letters to match the conventional format\n",
    "filing_ID_list['ISIN_id'] = filing_ID_list.ISIN_id.str.upper()\n",
    "filing_ID_list['CUSIP_id'] = filing_ID_list.CUSIP_id.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check of final Filing ID list dataframe\n",
    "filing_ID_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining whether each file is for a fix or float bond and adding to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to determine whether the bond note is for a fix or float interest rate. Do do this we create an empty list\n",
    "# and a function to count the number of times the words 'fix' or 'float' are used in the file text and create a list\n",
    "# for each file\n",
    "\n",
    "coupon_count_list = []\n",
    "\n",
    "def fix_or_float (list_of_files):\n",
    "    for file in list_of_files:\n",
    "        page = open('data/'+file)\n",
    "        file_name = BS(page.read()).text.lower()\n",
    "        \n",
    "        fix_count = len(re.findall('fix', file_name))\n",
    "        \n",
    "        float_count = len(re.findall('float', file_name))\n",
    "        \n",
    "        coupon_count_list.append((file, fix_count, float_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the word counting function across the list of files\n",
    "fix_or_float(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of fix/float word counts into a dataframe\n",
    "coupon_type = pd.DataFrame(coupon_count_list, columns = ['file', 'fix_count', 'float_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the count of 'fix' is greater than or equal to 'float' call the bond 'fix', otherwise call it 'float'\n",
    "coupon_type['coupon_type_code'] = (coupon_type['fix_count'] >= coupon_type['float_count']).astype(str)\n",
    "coupon_type['coupon_type_code'] = coupon_type['coupon_type_code'].str.replace('True', 'fix')\n",
    "coupon_type['coupon_type_code'] = coupon_type['coupon_type_code'].str.replace('False', 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the two needed columns, file name and whether it is fix or float\n",
    "coupon_type = coupon_type[['file', 'coupon_type_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to ensure all is well\n",
    "coupon_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the new coupon_type_code column onto the master dataframe with all the filing information\n",
    "filing_ID_list = filing_ID_list.merge(coupon_type, on='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check of the final filing information dataframe\n",
    "filing_ID_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the cleaned final file information as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataframe as a csv file\n",
    "filing_ID_list.to_csv('data/filing_ID_list.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
